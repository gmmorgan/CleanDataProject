# Getting and Cleaning Data Peer Assessment Project

As required by the license in README.txt, I acknowledge these people and this journal:
 Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012
 
 This is a generated file, produced by running _"really_run_analysis.R"_ on the file _"analysis.Rmd"_to produce _"Run_analysis.R"_, "README.txt"_ and _"Codebook.txt"_ using _knit()_ and _purl()_ from the _knitr_ library.
## Uncompress, load and merge the data.
There should be a file "getdata%@Fprojectfiles%2FUCI HAR Dataset.zip" in your working directory.
We un-compress this.
Load the data from each of test and train, and merge these into a single data frame.
```{r loaddata}
unzip("getdata%2Fprojectfiles%2FUCI HAR Dataset.zip")

base.dir = "UCI HAR Dataset"                # this is our dataset
# knitr does not play well with setwd(), so everything is relative file paths.
# Helper function to assemble file paths.
datafile = function(...){
    file.path(base.dir, ...)
}

# A helper function to load test or training data
get.data = function(directory, subject.file, activity.file, data.file){
    subjects = read.table(datafile(directory, subject.file))
    names(subjects)="Subject"

    activities = read.table(datafile(directory, activity.file))
    names(activities)="Activity"
    data = read.table(datafile(directory, data.file))
    full.data = data.frame(subjects, activities, data)
    full.data
    }

# load test directory
test.data = get.data("test", "subject_test.txt", "y_test.txt", "X_test.txt")

# load training directory
training.data = get.data("train", "subject_train.txt", "y_train.txt", "X_train.txt")

# merge data
all.data = rbind(test.data, training.data)
```
## Extract means and standard deviations.

Extract only the means and stds for each measurement.
Activity and subject are not measurements, so they stay.
The standard deviations are clearly identified by "std()"
The means are more troublesome. By my understanding of the description in features_info.txt,
both"mean()" and "meanFreq()" identify means, but the measurements containing "Mean" are are 
derived from means, but are not themselves means.
They represent angle measurements based on means.
I therefore exclude them.

If this is not satisfactory, they can easily be included.

The file "features.txt" contains useful header information that we need

We call the data frame we create _"chopped"_ .
```{r extract.means}
features = read.table(datafile("features.txt"), 
                      colClasses=c("integer",              # line number
                      "character"))[,2]                    # feature name
stds = grep("std\\(\\)", features)
angleMeans = grep("Mean", features)
means = grep("mean\\(\\)", features)
meanFreqs = grep("meanFreq\\(\\)", features)
# We must not forget that the first two columns are our subject and activity columns
# so everything else is offset by two.
selected.features = c(means,
                     meanFreqs,
                     #angleMeans,  # don't want this
                     stds)

chopped = all.data[c(1:2, selected.features+2)]    # don't forget offset for first two columns
```
## Label the data.
We need to _sanitize_ the column names that are obtained from the file _"features.txt"_.
We need to some ad-hoc cleaning of the column names to ensure no
horrors occur with the "$" operator.
We replace any number of punctuation symbols with dots, and then remove any remaining trailing dots that serve no useful purpose.
```{r sanitize.names}
# replace any number of punctuation characters with a single dot.
sanitized.features = gsub("[[:punct:]]+",".",features)
# remove any remaining trailing dots
sanitized.features =  gsub("\\.$","", sanitized.features)

names(chopped) = c(names(chopped[1:2]), sanitized.features[selected.features])
```

Lets assign some meaningful activity names
These are in the file _"activity_labels.txt"_.
```{r activiy.name}
activity.df = read.table(datafile("activity_labels.txt"))
chopped$Activity = activity.df[chopped$Activity,2]
```
Finally, Subject is probably best treated as a factor.
```{r factor.subject}
chopped$Subject = factor(chopped$Subject)
```
## Save the tidy data.
Create my tidy data by aggregating the measured data across _Subject_ and _Activity_ of the _"chopped"_ data, calculating the means.
It is written as a file _"tidy_data.txt"_ in the working directory.
```{r create.tidy.data}
tidy.data = aggregate(chopped[-c(1,2)], 
                      by=list(Subject=chopped$Subject, 
                              Activity=chopped$Activity), 
                      FUN=mean)

write.csv(tidy.data, file="tidy_data.txt", row.names=FALSE)
```
Prepare a code book identifying the tidy data we have created.
```{r codebook}
# Create a code book
# sink() does not work well with knitr, must isolate it in {}
{
    sink("Codebook.txt")
    cat("Code Book for tidy_data.txt\n")
    cat("\n\n")
    cat("Subject is a factor with the following levels:\n")
    str(tidy.data$Subject)
    cat("\n\n")
    cat("Activity is a factor with the following levels:\n")
    print(data.frame("Activity"=levels(tidy.data$Activity)))
    cat("\n\n")
    cat("The remaining columns contain means and standard deviations for various measurements\n")
    cat("All values are numeric.\n")
    cat("The original data names have had punctuation removed so the column names can be used safely.\n")
    cat("Please consult the README.txt for the original data for further clarification\n")
    print(data.frame("Original Names"=features[selected.features], 
                 row.names=sanitized.features[selected.features]))
    sink()
}
```




